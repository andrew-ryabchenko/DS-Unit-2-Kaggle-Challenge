{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle Challenge Random Forest Tuning  and Final  Submission.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMYS1U9HOFqQ9DzJ/6eSCHK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrew-ryabchenko/DS-Unit-2-Kaggle-Challenge/blob/master/Kaggle_Challenge_Random_Forest_Tuning_and_Final_Submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6SYjSAYcW_m",
        "outputId": "c6a22e26-51ae-4185-e542-0c2ab993f8a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install category_encoders;"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.6/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.18.5)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.1.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.17.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQo6zpeTjHIx"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from category_encoders import OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from statistics import mean\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from category_encoders.ordinal import OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.compose import make_column_selector"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5fhd3Io5taG"
      },
      "source": [
        "train_labels = pd.read_csv('https://raw.githubusercontent.com/andrew-ryabchenko/DS-Unit-2-Kaggle-Challenge/master/train_labels.csv')\n",
        "\n",
        "train_data = pd.read_csv('https://raw.githubusercontent.com/andrew-ryabchenko/DS-Unit-2-Kaggle-Challenge/master/train_features.csv', parse_dates = ['date_recorded'])\n",
        "\n",
        "test_features = pd.read_csv('https://raw.githubusercontent.com/andrew-ryabchenko/DS-Unit-2-Kaggle-Challenge/master/test_features.csv', parse_dates = ['date_recorded'])\n",
        "\n",
        "pop_data = pd.read_csv('https://raw.githubusercontent.com/andrew-ryabchenko/DS-Unit-2-Kaggle-Challenge/master/tanzania_pop_2012.csv')\n",
        "\n",
        "data = pd.merge(left=train_data, right=train_labels, on='id')"
      ],
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QsUciEoYHU3"
      },
      "source": [
        "assert len(data) == len(train_data) == len(train_labels), 'Ooops... something went wrong...'"
      ],
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj5XYkwbrlOG"
      },
      "source": [
        "* Columns to merge on in **pop_data**\n",
        "> Reg_Name, Dis_Name, Ward_Name\n",
        "\n",
        "* Columns to merge on in **data**\n",
        "> region, lga, ward\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C3ZDaPvz6wh"
      },
      "source": [
        "def merge(data, population):\n",
        "  data = data.copy()\n",
        "  population = population.copy()\n",
        "  # rename Dis_Name value 'Moshi Municipal' to 'Moshi Urban' so it matches training data\n",
        "  population['Dis_Name'] = population['Dis_Name'].apply(lambda x: 'Moshi Urban' if x == 'Moshi Municipal' else x)\n",
        "\n",
        "  # create a subset of pop_data with only features we need\n",
        "  population = population[['Reg_Name', 'Dis_Name', 'Ward_Name', 'total_both', 'area_km2', 'Pop_Den', 'ward_type']]\n",
        "\n",
        "  # Prepare object values for merging\n",
        "  population['Reg_Name'] = population['Reg_Name'].str.strip().str.lower()\n",
        "  population['Ward_Name'] = population['Ward_Name'].str.strip().str.lower()\n",
        "  population['Dis_Name'] = population['Dis_Name'].str.strip().str.lower()\n",
        "\n",
        "  data['region'] = data['region'].str.strip().str.lower()\n",
        "  data['lga'] = data['lga'].str.strip().str.lower()\n",
        "  data['ward'] = data['ward'].str.strip().str.lower()\n",
        "\n",
        "  # Give columns the same names in both datasets\n",
        "  population.rename({'Dis_Code':'district_code', 'Reg_Code':'region_code', 'Reg_Name': 'region', 'Dis_Name':'lga', 'Ward_Name': 'ward'}, axis = 1, inplace=True)\n",
        "  \n",
        "  # Merge\n",
        "  data_full = pd.merge(left = data, right = population, on = ['lga','region','ward'], how = 'left')\n",
        "\n",
        "  assert len(data) == len(data_full), 'Ooops... Something went wrong...'\n",
        "\n",
        "  return data_full"
      ],
      "execution_count": 283,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GV-pr_-9DHk"
      },
      "source": [
        "def wrangle(data):\n",
        "  data = data.copy()\n",
        "  # Drop high-cardinality features\n",
        "  \n",
        "  mask = data.select_dtypes('object').nunique() > 130\n",
        "  cols_to_drop = (data.select_dtypes('object').nunique() > 130)[mask].index\n",
        "  data.drop(columns=cols_to_drop, inplace=True)\n",
        "  data.drop(columns = ['extraction_type_group','extraction_type_class', 'quantity_group', 'date_recorded', 'scheme_management',\n",
        "                       'population', 'num_private','payment_type','waterpoint_type_group', 'recorded_by', 'public_meeting', 'permit'], inplace = True)\n",
        "\n",
        "  #Impute Columns\n",
        "  columns_n = make_column_selector(dtype_include = 'number')\n",
        "  columns_0 = make_column_selector(dtype_include = 'object')\n",
        "\n",
        "  imp_o = SimpleImputer(strategy='most_frequent')\n",
        "  imp_n = SimpleImputer()\n",
        "\n",
        "  data[columns_n(data)] = imp_n.fit_transform(data[columns_n(data)])\n",
        "  data[columns_o(data)] = imp_o.fit_transform(data[columns_o(data)])\n",
        "\n",
        "  # Fix null island issue\n",
        "  if (len(data) > 59000):\n",
        "    data = data[~(data['longitude']==0)]\n",
        "\n",
        "  return data"
      ],
      "execution_count": 282,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsYSUGRi8uL-"
      },
      "source": [
        "data_clean = wrangle(merge(data, pop_data))"
      ],
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5OS-GOqSN9I"
      },
      "source": [
        "# Create feature matrix and target vector\n",
        "\n",
        "X = data_clean.drop(columns=['id', 'status_group'])\n",
        "y = data_clean['status_group']\n",
        "\n",
        "assert len(X) == len(y), 'X and y are diffferent lenght'"
      ],
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-GUaDN3BCPg"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.33, random_state=42)\n",
        "\n",
        "model = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    RandomForestClassifier(random_state=42,max_depth = 35, max_samples= 0.4, n_estimators=300)\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train);"
      ],
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNb3FLsXBvKr",
        "outputId": "1a263760-a874-4175-d8c4-8f1220aca1e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.score(X_val, y_val)"
      ],
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8068929229150223"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 292
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2-xZPTHOeg-"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
      ],
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGY1QFgFpGFR"
      },
      "source": [
        "params = {'randomforestclassifier__max_depth': range(15,86,10),\n",
        "          'randomforestclassifier__max_samples': np.arange(0,0.8,0.1),\n",
        "          'randomforestclassifier__n_estimators': range(10,101,10)\n",
        "          }"
      ],
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXNIX0tS-tpw"
      },
      "source": [
        "grid_search = RandomizedSearchCV(\n",
        "    model,\n",
        "    params,\n",
        "    n_jobs = -1,\n",
        "    verbose=True,\n",
        "    cv=5,\n",
        "    random_state = 42\n",
        ")\n",
        "grid_search.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTSLCjdPFEtH",
        "outputId": "42101384-037e-4eb4-e6f1-f2a7f935f19e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "grid_search.best_params_"
      ],
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'randomforestclassifier__max_depth': 85,\n",
              " 'randomforestclassifier__max_samples': 0.30000000000000004,\n",
              " 'randomforestclassifier__n_estimators': 80}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 295
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16FebliaG_Zf"
      },
      "source": [
        "tuned_model = grid_search.best_estimator_"
      ],
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fam1qLMc2cIR"
      },
      "source": [
        "#create submission\n",
        "XT = wrangle(merge(test_features, pop_data))\n",
        "predictions = tuned_model.predict(XT.drop(columns=['id']))\n",
        "assert len(predictions) == len(test_features), 'Ooops, something went wrong...'"
      ],
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsQ7Ez8E8oBR"
      },
      "source": [
        "DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge/master/data/'\n",
        "sample_submission = pd.read_csv(DATA_PATH+'waterpumps/sample_submission.csv')\n",
        "submission = sample_submission.copy()\n",
        "submission['status_group'] = predictions\n",
        "submission.to_csv('kaggle_waterpump_challenge_submission_4.csv', index=False)"
      ],
      "execution_count": 301,
      "outputs": []
    }
  ]
}